{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from pynput.keyboard import Key, Controller\n",
    "# import screen_brightness_control as sbc\n",
    "from keras.models import load_model\n",
    "\n",
    "from lib.data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n",
      "model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "root_directory = r'<path>\\dataset'\n",
    "labels_csv_path = os.path.join(root_directory, 'labels_extracted.csv')\n",
    "train_csv_path = os.path.join(root_directory, 'train_extracted.csv')\n",
    "val_csv_path = os.path.join(root_directory, 'validation_extracted.csv')\n",
    "\n",
    "data = DataLoader(labels_csv_path, train_csv_path, val_csv_path)\n",
    "\n",
    "print('loading model...')\n",
    "model = load_model('output/models/resnet_101.h5', compile=False)\n",
    "print('model loaded successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_gesture_action_mapping = {\n",
    "    'Swiping Left': 'fast forward 10 seconds',\n",
    "    'Swiping Right': 'rewind 10 seconds',\n",
    "    'Swiping Down': 'previous video',\n",
    "    'Swiping Up': 'next video',\n",
    "    'Sliding Two Fingers Down': 'decrease volume',\n",
    "    'Sliding Two Fingers Up': 'increase volume',\n",
    "    'Thumb Down': 'mute / unmute',\n",
    "    'Thumb Up': 'enter / exit full screen',\n",
    "    'Stop Sign': 'play / pause',\n",
    "    'No gesture': 'no action'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 96\n",
    "HEIGHT = 64\n",
    "N_FRAMES = 16\n",
    "\n",
    "buffer = []\n",
    "predicted_value = 9\n",
    "hand_gesture = \"\"\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 400)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 400)\n",
    "keyboard = Controller()\n",
    "\n",
    "while(cam.isOpened()):\n",
    "    \n",
    "    return_value, frame = cam.read()\n",
    "    if return_value:\n",
    "        image = cv2.resize(frame, (WIDTH, HEIGHT))\n",
    "        image = image/255.0\n",
    "        buffer.append(image)\n",
    "        \n",
    "        # if buffer is appended with n frames\n",
    "        if(len(buffer)%N_FRAMES == 0):\n",
    "            buffer = np.expand_dims(buffer, 0)\n",
    "            predicted_value = np.argmax(model.predict(buffer, verbose=0))\n",
    "\n",
    "            if(predicted_value == 0):\n",
    "                keyboard.tap('l')\n",
    "                \n",
    "            elif (predicted_value == 1):\n",
    "                keyboard.tap('j')\n",
    "                \n",
    "            elif (predicted_value == 2):\n",
    "                keyboard.press(Key.shift)\n",
    "                keyboard.tap('p')\n",
    "                keyboard.release(Key.shift)\n",
    "                \n",
    "            elif (predicted_value== 3):\n",
    "                keyboard.press(Key.shift)\n",
    "                keyboard.tap('n')\n",
    "                keyboard.release(Key.shift)\n",
    "                \n",
    "            elif (predicted_value == 4):\n",
    "                keyboard.tap(Key.down)\n",
    "                \n",
    "            elif (predicted_value == 5):\n",
    "                keyboard.tap(Key.up)\n",
    "                \n",
    "            elif (predicted_value == 6):\n",
    "                keyboard.tap('m')\n",
    "\n",
    "            elif (predicted_value == 7):\n",
    "                keyboard.tap('f')\n",
    "                \n",
    "            elif (predicted_value == 8):\n",
    "                keyboard.tap('k')\n",
    "                \n",
    "            elif (predicted_value == 9):\n",
    "                pass\n",
    "\n",
    "            cv2.imshow('frame', frame)\n",
    "            buffer = []\n",
    "            \n",
    "        gesture = data.int_to_label[predicted_value]\n",
    "        text = f'{gesture} -> {hand_gesture_action_mapping[gesture]}'\n",
    "        cv2.putText(frame, text, (20, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 3)\n",
    "        cv2.imshow('frame',frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "9481360d7190b8c4c719fedfc399c27f4a710e77023a7f81d67e5ad3678c6894"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
